{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. Premade Estimators\n",
    "\n",
    "본 실습에서는 Estimators를 사용하여 TensorFlow의 Iris classification 문제를 해결하는 방법을 설명합니다.\n",
    "\n",
    "Estimator는 TensorFlow의 완전한 Model의 높은 수준의 표현으로, 간편한 확장 및 비동기식 교육을 위해 설계되었습니다.\n",
    "\n",
    "TensorFlow 2.0에서는 Keras API가 이와 같은 많은 작업을 수행할 수 있으며, 보다 쉽게 배울 수 있는 API로 여겨집니다.\n",
    "\n",
    "새로 시작하는 경우 Keras부터 시작하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First things first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작하기 위해 먼저 TensorFlow와 필요한 여러 라이브러리를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 2. The data set\n",
    "\n",
    "이 문서의 샘플 프로그램은 Iris 꽃들을 그들의 꽃받침과 꽃잎의 크기에 따라 3개의 다른 종으로 분류하는 모델을 만들고 테스트합니다.\n",
    "\n",
    "Iris 데이터 세트를 사용하여 모델을 train 합니다. \n",
    "\n",
    "***\n",
    "\n",
    "Iris 데이터 세트에는 4가지 feature와 1개의 label이 있습니다. \n",
    "\n",
    "4가지 feature는 개별 Iris 꽃의 다음과 같은 식물학적 특성을 식별합니다.\n",
    "\n",
    "   * sepal length (꽃받침 길이)\n",
    "   * sepal width (꽃받침 너비)\n",
    "   * petal length (꽃잎 길이)\n",
    "   * petal width (꽃잎 너비)\n",
    "   \n",
    "이 정보를 기반으로 데이터를 구문 분석하는 데 유용한 상수를 몇 개 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, Keras와 Pandas를 사용하여 Iris 데이터 세트를 다운로드하고 구문 분석합니다. \n",
    "\n",
    "training 및 testing을 위해 별도의 데이터 세트를 보관합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 검사하여 4개의 float feature columns과 1개의 int32 label이 있는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터 세트에 대해 labels를 분할하여 모델이 predict하도록 train합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# The label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 3. Overview of programming with Estimators\n",
    "\n",
    "이제 데이터가 설정되었으므로 TensorFlow Estimator를 사용하여 모델을 정의할 수 있습니다.\n",
    "\n",
    "Estimator는 ```tf.estimator.Estimator```에서 파생된 클래스입니다.\n",
    "\n",
    "TensorFlow는 일반적인 ML 알고리즘을 구현하기 위한 ```tf.estimator```(예: ```LinearRegressor```) collection을 제공합니다.\n",
    "\n",
    "그 외에도 own custom Estimators를 작성할 수 있습니다.\n",
    "\n",
    "***\n",
    "\n",
    "처음 시작할 때는 pre-made Estimators를 사용하는 것이 좋습니다.\n",
    "\n",
    "pre-made Estimators를 기반으로 TensorFlow 프로그램을 작성하려면 다음 작업을 수행해야 합니다.\n",
    "\n",
    "   * 하나 이상의 input function을 생성합니다.\n",
    "   \n",
    "   * model's feature columns를 정의합니다.\n",
    "   \n",
    "   * feature columns와 다양한 hyperparameters를 지정하여 Estimator를 인스턴스화합니다.\n",
    "   \n",
    "   * 데이터 소스로 적절한 input function을 전달하여 Estimator object에서 하나 이상의 method를 호출합니다.\n",
    "   \n",
    "Iris classification을 위해 이러한 작업이 어떻게 구현되는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 4. Create input functions\n",
    "\n",
    "training, evaluating 및 prediction을 위한 데이터를 제공하기 위한 input functions를 생성해야 합니다.\n",
    "\n",
    "input function는 ```tf.data.Dataset``` 객체를 반환하여 다음의 two-element tuple을 출력하는 함수입니다.\n",
    "\n",
    "   * features - Python dictionary 이며, 다음과 같습니다.\n",
    "      * 각 key는 feature의 이름입니다.\n",
    "      * 각 value는 해당 feature의 values를 모두 포함하는 array입니다.\n",
    "      \n",
    "   * label - 모든 example에 대한 values of the label을 포함하는 array입니다.\n",
    "   \n",
    "다음은 input function의 format을 보여 주는 간단한 구현 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input function은 원하는 대로 features dictionary 및 label list를 생성할 수 있습니다. \n",
    "\n",
    "그러나 모든 종류의 데이터를 구문 분석할 수 있는 TensorFlow의 Dataset API를 사용하는 것이 좋습니다.\n",
    "\n",
    "Dataset API는 많은 일반적인 사례를 처리할 수 있습니다. \n",
    "\n",
    "예를 들어, Dataset API를 사용하면 대용량 collection으로부터 records를 쉽게 읽고 동시에 이를 single stream에 결합할 수 있습니다.\n",
    "\n",
    "***\n",
    "\n",
    "이 예에서는 pandas를 사용하여 데이터를 로드하고 in-memory data로 input pipeline을 구축하려고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 5. Define the feature columns\n",
    "\n",
    "feature column은 모델에서 features dictionary의 raw input data를 사용하는 방법을 설명하는 object입니다.\n",
    "\n",
    "Estimator model을 build할 때, 모형에 사용하기를 원하는 각 features를 설명하는 list of feature columns을 이 모델에 전달합니다.\n",
    "\n",
    "```tf.feature_column``` 모듈은 model에 데이터를 나타내는 여러 가지 옵션을 제공합니다.\n",
    "\n",
    "***\n",
    "\n",
    "Iris의 경우, 4개의 raw features는 numeric values이므로, \n",
    "\n",
    "Estimator mode에 4개의 features를 각각 32비트 부동 소수점(32-bit floating-point) 값으로 나타내도록 지시하는 list of feature columns을 build합니다.\n",
    "\n",
    "따라서 feature column을 생성할 코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], dtype='object')\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "print(train.keys())\n",
    "\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "pprint.pprint(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature columns는 여기서 보여드리는 것보다 훨씬 더 정교할 수 있습니다.\n",
    "\n",
    "이제 model이 raw features를 나타내는 방법에 대한 설명을 얻었으므로, estimator를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 6. Instantiate an estimator\n",
    "\n",
    "Iris 문제는 전형적인 classification 문제입니다.\n",
    "\n",
    "다행히도 TensorFlow는 다음과 같은 몇 가지 pre-made classifier Estimators를 제공합니다.\n",
    "\n",
    "   * ```tf.estimator.DNNClassifier``` - multi-class classification를 수행하는 deep models을 위한 것입니다.\n",
    "\n",
    "   * ```tf.estimator.DNNLinearCombinedClassifier``` - wide & deep models을 위한 것입니다.\n",
    "\n",
    "   * ```tf.estimator.LinearClassifier``` - linear(선형) models을 기반으로 하는 classifiers를 위한 것입니다.\n",
    "\n",
    "\n",
    "Iris 문제의 경우 ```tf.estimator.DNNClassifier```가 최선의 선택인 것 같습니다.\n",
    "\n",
    "다음은 이 Estimator를 인스턴스화하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmpfbz03npz\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\CHANGY~1\\\\AppData\\\\Local\\\\Temp\\\\tmpfbz03npz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 object at 0x000001CDB882BCC8>\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 7. Train, Evaluate, and Predict\n",
    "\n",
    "\n",
    "이제 Estimator object가 있으므로 methods를 호출하여 다음 작업을 수행할 수 있습니다.\n",
    "\n",
    "   * Train the model.\n",
    "\n",
    "   * Evaluate the trained model.\n",
    "\n",
    "   * Use the trained model to make predictions.\n",
    "\n",
    "***\n",
    "\n",
    "### Train the model\n",
    "\n",
    "\n",
    "다음과 같이 Estimator's train method를 호출하여 모델을 train합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmpfbz03npz\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.0654345, step = 0\n",
      "INFO:tensorflow:global_step/sec: 613.362\n",
      "INFO:tensorflow:loss = 1.1127998, step = 100 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.509\n",
      "INFO:tensorflow:loss = 1.0141568, step = 200 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 877\n",
      "INFO:tensorflow:loss = 0.96589696, step = 300 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.751\n",
      "INFO:tensorflow:loss = 0.9278718, step = 400 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.76\n",
      "INFO:tensorflow:loss = 0.8876071, step = 500 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.755\n",
      "INFO:tensorflow:loss = 0.8565875, step = 600 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.875\n",
      "INFO:tensorflow:loss = 0.83273506, step = 700 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.757\n",
      "INFO:tensorflow:loss = 0.8040186, step = 800 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.705\n",
      "INFO:tensorflow:loss = 0.7724534, step = 900 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.691\n",
      "INFO:tensorflow:loss = 0.75899553, step = 1000 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.76\n",
      "INFO:tensorflow:loss = 0.72848266, step = 1100 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.695\n",
      "INFO:tensorflow:loss = 0.711177, step = 1200 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.76\n",
      "INFO:tensorflow:loss = 0.69389856, step = 1300 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.514\n",
      "INFO:tensorflow:loss = 0.68295294, step = 1400 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.751\n",
      "INFO:tensorflow:loss = 0.6617793, step = 1500 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.875\n",
      "INFO:tensorflow:loss = 0.65262926, step = 1600 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.662\n",
      "INFO:tensorflow:loss = 0.6337406, step = 1700 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.998\n",
      "INFO:tensorflow:loss = 0.62352926, step = 1800 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.264\n",
      "INFO:tensorflow:loss = 0.61051714, step = 1900 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.88\n",
      "INFO:tensorflow:loss = 0.60333234, step = 2000 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.5927135, step = 2100 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.998\n",
      "INFO:tensorflow:loss = 0.5955957, step = 2200 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.757\n",
      "INFO:tensorflow:loss = 0.57027465, step = 2300 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.759\n",
      "INFO:tensorflow:loss = 0.57036114, step = 2400 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.369\n",
      "INFO:tensorflow:loss = 0.564692, step = 2500 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.369\n",
      "INFO:tensorflow:loss = 0.54811835, step = 2600 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.766\n",
      "INFO:tensorflow:loss = 0.53930074, step = 2700 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.991\n",
      "INFO:tensorflow:loss = 0.5269209, step = 2800 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.998\n",
      "INFO:tensorflow:loss = 0.5275655, step = 2900 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.51851976, step = 3000 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.697\n",
      "INFO:tensorflow:loss = 0.5132651, step = 3100 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.701\n",
      "INFO:tensorflow:loss = 0.5062199, step = 3200 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.37\n",
      "INFO:tensorflow:loss = 0.49933052, step = 3300 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.759\n",
      "INFO:tensorflow:loss = 0.49276486, step = 3400 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.759\n",
      "INFO:tensorflow:loss = 0.50121033, step = 3500 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.365\n",
      "INFO:tensorflow:loss = 0.48781103, step = 3600 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.156\n",
      "INFO:tensorflow:loss = 0.4933793, step = 3700 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.361\n",
      "INFO:tensorflow:loss = 0.47496098, step = 3800 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.703\n",
      "INFO:tensorflow:loss = 0.464924, step = 3900 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.887\n",
      "INFO:tensorflow:loss = 0.4716813, step = 4000 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.656\n",
      "INFO:tensorflow:loss = 0.46481287, step = 4100 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.699\n",
      "INFO:tensorflow:loss = 0.46161246, step = 4200 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.759\n",
      "INFO:tensorflow:loss = 0.46422935, step = 4300 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.695\n",
      "INFO:tensorflow:loss = 0.44071603, step = 4400 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.003\n",
      "INFO:tensorflow:loss = 0.44187397, step = 4500 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.991\n",
      "INFO:tensorflow:loss = 0.45211762, step = 4600 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.755\n",
      "INFO:tensorflow:loss = 0.43391883, step = 4700 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 877\n",
      "INFO:tensorflow:loss = 0.42971766, step = 4800 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.4251157, step = 4900 (0.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmpfbz03npz\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.4264481.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1cdb882bcc8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda로 ```input_fn```을 호출하여 인자를 캡처하는 동시에 \n",
    "\n",
    "Estimator에서 예상한 대로 인자를 사용하지 않는 input function을 제공합니다.\n",
    "\n",
    "```steps``` 인자는 여러 training steps가 끝난 후 training을 중지하는 방법을 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Evaluate the trained model\n",
    "\n",
    "이제 모델이 train 했으므로 성능에 대한 몇 가지 통계를 얻을 수 있습니다. \n",
    "\n",
    "다음 코드 블록은 test data에 대해 학습된 모델의 accuracy(정확도)를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-04T22:29:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmpfbz03npz\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.25106s\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-04-22:29:45\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.5072904, global_step = 5000, loss = 0.5072904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmpfbz03npz\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train method에 대한 호출과 달리, evaluate에 대한 steps argument는 통과하지 않았습니다.\n",
    "\n",
    "evaluate에 대한 ```input_fn```은 단 하나의 데이터만 생성합니다.\n",
    "\n",
    "```eval_result``` dictionary에는 \n",
    "\n",
    "   * average_loss(mean loss per sample)\n",
    "   * the loss (mean loss per mini-batch)\n",
    "   * estimator's global_step 값(training 반복 횟수)\n",
    "   \n",
    "등이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Making predictions (inferring) from the trained model\n",
    "\n",
    "이제 좋은 평가 결과를 만들어내는 훈련된 모델을 갖게 되었습니다.\n",
    "\n",
    "이제 몇몇 라벨이 붙어 있지 않은 측정(unlabeled measurements)을 바탕으로 Iris 꽃의 종을 예측하기 위해 훈련된 모델을 사용할 수 있습니다.\n",
    "\n",
    "training 및 evaluation과 마찬가지로, 단일 함수 호출(single function call)을 사용하여 prediction해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```predict``` method는 Python iterable을 반환하여, 각 example에 대한 예측 결과 dictionary를 생성합니다. \n",
    "\n",
    "다음 코드는 몇 가지 predictions와 그 확률을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\CHANGY~1\\AppData\\Local\\Temp\\tmph8gm4yk3\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (74.0%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (44.0%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (60.3%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
